{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsansao/teic-20231/blob/main/TEIC_Licao35_API_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzKBEoyyVUZZ"
      },
      "source": [
        "# üöÄ Exemplo de Uso da API do Gemini no Google Colab\n",
        "\n",
        "Este notebook demonstra como come√ßar a usar a API do Google Gemini (atrav√©s da biblioteca `google-generativeai`) para:\n",
        "1.  Instalar a biblioteca.\n",
        "2.  Configurar sua API Key de forma segura.\n",
        "3.  Gerar texto a partir de um prompt simples.\n",
        "4.  Manter uma conversa (chat) com hist√≥rico.\n",
        "5.  Usar a capacidade multimodal (enviar texto + imagem)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFTwtHcHVUZb"
      },
      "source": [
        "## Passo 1: Instala√ß√£o\n",
        "\n",
        "Primeiro, precisamos instalar a biblioteca Python do Google."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sfnNGOw4VUZb"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8tGhPg9VUZc"
      },
      "source": [
        "## Passo 2: Configura√ß√£o da API Key\n",
        "\n",
        "Para usar a API, voc√™ precisa de uma API Key.\n",
        "\n",
        "1.  Acesse o [Google AI Studio](https://aistudio.google.com/app/apikey) para gerar sua chave.\n",
        "2.  **IMPORTANTE:** Nunca cole sua chave diretamente no c√≥digo. Use o gerenciador de \"Secrets\" do Colab.\n",
        "3.  Clique no √≠cone de **chave** (üîë) na barra lateral esquerda.\n",
        "4.  Adicione um novo segredo chamado `GOOGLE_API_KEY` e cole sua chave l√°."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPGwa6opVUZc",
        "outputId": "7caa189c-6bb6-427a-ea80-bccedef0f0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key configurada com sucesso!\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Tenta buscar a API Key dos Secrets do Colab\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"API Key configurada com sucesso!\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Erro: 'GOOGLE_API_KEY' n√£o encontrada nos Secrets do Colab.\")\n",
        "    print(\"Por favor, adicione sua API Key na aba 'Secrets' (√≠cone de chave) √† esquerda e nomeie-a 'GOOGLE_API_KEY'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro: {e}\")\n",
        "    print(\"Certifique-se de que sua API Key √© v√°lida e foi adicionada corretamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT60uX4QVUZd"
      },
      "source": [
        "## Passo 3: Exemplo 1 - Gera√ß√£o de Texto Simples\n",
        "\n",
        "Este √© o caso de uso mais b√°sico: enviar um prompt e receber uma resposta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "FyrRtkezVUZd",
        "outputId": "0fc3489d-34e0-4d89-8fbf-d0b56ff6b3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enviando prompt: Escreva um poema curto sobre o Brasil, em 4 linhas.\n",
            "\n",
            "--- Resposta do Gemini ---\n",
            "Verde e amarelo, luz que aquece,\n",
            "O samba corre e nunca arrefece.\n",
            "A floresta guarda o mar e o sol,\n",
            "Brasil, eterno e vasto farol.\n"
          ]
        }
      ],
      "source": [
        "# Configura o modelo\n",
        "# Vamos usar o gemini-2.5-flash-preview-09-2025, que √© r√°pido e eficiente\n",
        "model = genai.GenerativeModel('gemini-2.5-flash-preview-09-2025')\n",
        "\n",
        "# Envia um prompt\n",
        "prompt = \"Escreva um poema curto sobre o Brasil, em 4 linhas.\"\n",
        "print(f\"Enviando prompt: {prompt}\\n\")\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Imprime a resposta\n",
        "try:\n",
        "    print(\"--- Resposta do Gemini ---\")\n",
        "    print(response.text)\n",
        "except ValueError as e:\n",
        "    print(f\"Erro ao gerar conte√∫do. O modelo pode ter bloqueado a resposta. Detalhes: {e}\")\n",
        "    print(f\"Resposta completa: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qur4FEmVUZe"
      },
      "source": [
        "## Passo 4: Exemplo 2 - Chat (Conversa com Hist√≥rico)\n",
        "\n",
        "Para casos de uso como chatbots, voc√™ pode criar um objeto de chat que mant√©m o hist√≥rico da conversa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "R_zFUmoqVUZe",
        "outputId": "1f839c56-67ae-4f92-eb46-dfc1471acc60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usu√°rio: Qual √© a capital da Fran√ßa?\n",
            "\n",
            "Gemini: A capital da Fran√ßa √© **Paris**.\n",
            "\n",
            "Usu√°rio: E qual √© o principal ponto tur√≠stico de l√°?\n",
            "\n",
            "Gemini: O principal e mais famoso ponto tur√≠stico de Paris, sendo o seu s√≠mbolo m√°ximo, √© a **Torre Eiffel** (La Tour Eiffel).\n",
            "\n",
            "No entanto, o **Museu do Louvre** tamb√©m √© um ponto extremamente importante e mundialmente famoso, conhecido por abrigar obras como a Mona Lisa e a V√™nus de Milo.\n",
            "\n",
            "\n",
            "--- Hist√≥rico da Conversa Armazenado ---\n",
            "**user**: Qual √© a capital da Fran√ßa?\n",
            "**model**: A capital da Fran√ßa √© **Paris**.\n",
            "**user**: E qual √© o principal ponto tur√≠stico de l√°?\n",
            "**model**: O principal e mais famoso ponto tur√≠stico de Paris, sendo o seu s√≠mbolo m√°ximo, √© a **Torre Eiffel** (La Tour Eiffel).\n",
            "\n",
            "No entanto, o **Museu do Louvre** tamb√©m √© um ponto extremamente importante e mundialmente famoso, conhecido por abrigar obras como a Mona Lisa e a V√™nus de Milo.\n"
          ]
        }
      ],
      "source": [
        "# O modelo de chat mant√©m o hist√≥rico\n",
        "chat_model = genai.GenerativeModel('gemini-2.5-flash-preview-09-2025')\n",
        "chat = chat_model.start_chat(history=[])\n",
        "\n",
        "# Pergunta 1\n",
        "prompt1 = \"Qual √© a capital da Fran√ßa?\"\n",
        "print(f\"Usu√°rio: {prompt1}\\n\")\n",
        "\n",
        "response1 = chat.send_message(prompt1)\n",
        "print(f\"Gemini: {response1.text}\\n\")\n",
        "\n",
        "# Pergunta 2 (com contexto)\n",
        "prompt2 = \"E qual √© o principal ponto tur√≠stico de l√°?\"\n",
        "print(f\"Usu√°rio: {prompt2}\\n\")\n",
        "\n",
        "response2 = chat.send_message(prompt2)\n",
        "print(f\"Gemini: {response2.text}\\n\")\n",
        "\n",
        "# Opcional: ver o hist√≥rico\n",
        "print(\"\\n--- Hist√≥rico da Conversa Armazenado ---\")\n",
        "for message in chat.history:\n",
        "    # Exibindo apenas as partes de texto\n",
        "    print(f\"**{message.role}**: {message.parts[0].text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFkxb9TwVUZf"
      },
      "source": [
        "## Passo 5: Exemplo 3 - Multimodal (Texto e Imagem)\n",
        "\n",
        "O Gemini pode receber entradas que misturam texto e imagens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc4R4o2zVUZf",
        "outputId": "be5f3f41-e075-4a68-ef85-b6852c62ccab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagem 'pao_de_acucar.jpg' baixada.\n"
          ]
        }
      ],
      "source": [
        "# Primeiro, vamos baixar uma imagem de exemplo\n",
        "!wget -q -O pao_de_acucar.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Vista_do_Morro_Dona_Marta.jpg/1920px-Vista_do_Morro_Dona_Marta.jpg\n",
        "print(\"Imagem 'pao_de_acucar.jpg' baixada.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "WpK-NqZoVUZg",
        "outputId": "2c97fff7-e71d-4a3b-f13c-1ea00d386ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enviando prompt: Que lugar √© este e em que cidade ele fica? + [IMAGEM]\n",
            "\n",
            "--- Resposta do Gemini ---\n",
            "Este lugar ic√¥nico √© a **Ba√≠a de Guanabara**, com destaque para o famoso **P√£o de A√ß√∫car** e o **Morro da Urca** em primeiro plano.\n",
            "\n",
            "A cidade onde ele se localiza √©:\n",
            "\n",
            "**Rio de Janeiro, Brasil.**\n",
            "\n",
            "A foto foi tirada provavelmente de um ponto alto na zona sul ou central da cidade, como o **Corcovado** ou o **Mirante Dona Marta**, oferecendo uma vista panor√¢mica que engloba a Enseada de Botafogo (parcialmente vis√≠vel na esquerda) e a entrada da Ba√≠a de Guanabara.\n"
          ]
        }
      ],
      "source": [
        "import PIL.Image\n",
        "\n",
        "try:\n",
        "    img = PIL.Image.open('pao_de_acucar.jpg')\n",
        "\n",
        "    # Para multimodalidade, usamos o mesmo modelo flash\n",
        "    multimodal_model = genai.GenerativeModel('gemini-2.5-flash-preview-09-2025')\n",
        "\n",
        "    # Envia o prompt com texto e imagem\n",
        "    prompt_multimodal = \"Que lugar √© este e em que cidade ele fica?\"\n",
        "    print(f\"Enviando prompt: {prompt_multimodal} + [IMAGEM]\\n\")\n",
        "\n",
        "    response_multimodal = multimodal_model.generate_content([prompt_multimodal, img])\n",
        "\n",
        "    print(\"--- Resposta do Gemini ---\")\n",
        "    print(response_multimodal.text)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Erro: Arquivo 'pao_de_acucar.jpg' n√£o encontrado. Tente executar a c√©lula anterior novamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0exfMX3gVUZg"
      },
      "source": [
        "## Fim!\n",
        "\n",
        "Voc√™ aprendeu a usar a API do Gemini para as tarefas mais comuns. Sinta-se √† vontade para modificar os prompts e testar com suas pr√≥prias imagens."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}