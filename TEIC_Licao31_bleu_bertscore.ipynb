{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsansao/teic-20231/blob/main/TEIC_Licao31_bleu_bertscore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHOi4Qdpq35Y"
      },
      "source": [
        "# ü§ñ Comparando M√©tricas: BLEU vs. BERTScore\n",
        "\n",
        "Este notebook demonstra a diferen√ßa fundamental entre a m√©trica **BLEU** (baseada em *n-grams*) e a m√©trica **BERTScore** (baseada em *sem√¢ntica*).\n",
        "\n",
        "Vamos avaliar 4 senten√ßas \"candidatas\" contra 1 senten√ßa de \"refer√™ncia\" para ver como cada m√©trica reage.\n",
        "\n",
        "### O Cen√°rio\n",
        "* **BLEU:** Esperamos que pontue bem apenas quando as palavras *exatas* s√£o usadas.\n",
        "* **BERTScore:** Esperamos que pontue bem quando o *significado* √© semelhante, mesmo que as palavras sejam diferentes."
      ],
      "id": "AHOi4Qdpq35Y"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baUEV4_Mq35a",
        "outputId": "818c9e30-6516-4ab6-bae0-c979804be65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.57.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2025.10.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Instala√ß√£o das Bibliotecas\n",
        "# Vamos instalar a biblioteca bert-score e a nltk (para o BLEU)\n",
        "\n",
        "!pip install bert-score\n",
        "!pip install nltk"
      ],
      "id": "baUEV4_Mq35a"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "br6JPVvhq35a"
      },
      "outputs": [],
      "source": [
        "# @title 2. Importa√ß√µes\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from bert_score import score\n",
        "import pandas as pd\n",
        "\n",
        "# Usaremos uma fun√ß√£o de suaviza√ß√£o para o BLEU,\n",
        "# pois ele n√£o funciona bem em senten√ßas curtas sem isso.\n",
        "chen_smoothing = SmoothingFunction().method4"
      ],
      "id": "br6JPVvhq35a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxtDjSqsq35c"
      },
      "source": [
        "## 3. Defini√ß√£o das Senten√ßas de Teste\n",
        "\n",
        "Este √© o nosso caso de teste. Temos uma refer√™ncia (a tradu√ß√£o \"correta\") e quatro candidatos com caracter√≠sticas diferentes:\n",
        "\n",
        "1.  **Candidato 1 (Correspond√™ncia Exata):** Id√™ntico √† refer√™ncia.\n",
        "2.  **Candidato 2 (Par√°frase/Sem√¢ntico):** Significado id√™ntico, mas com sin√¥nimos.\n",
        "3.  **Candidato 3 (Sobreposi√ß√£o, Sentido Oposto):** Usa as mesmas palavras, mas o significado √© o oposto.\n",
        "4.  **Candidato 4 (Diferente):** Uma senten√ßa completamente aleat√≥ria."
      ],
      "id": "SxtDjSqsq35c"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JH0bW4u1q35c"
      },
      "outputs": [],
      "source": [
        "# @title 4. Nossas senten√ßas (em Portugu√™s)\n",
        "\n",
        "# A senten√ßa que consideramos \"correta\"\n",
        "referencia = \"O gato r√°pido pulou sobre o cachorro pregui√ßoso.\"\n",
        "\n",
        "# Lista de senten√ßas geradas para comparar\n",
        "candidatos = [\n",
        "    # 1. Correspond√™ncia Exata\n",
        "    \"O gato r√°pido pulou sobre o cachorro pregui√ßoso.\",\n",
        "\n",
        "    # 2. Par√°frase (Sin√¥nimos, mesmo significado)\n",
        "    \"O felino √°gil saltou por cima do c√£o sonolento.\",\n",
        "\n",
        "    # 3. Sobreposi√ß√£o de palavras (Significado oposto)\n",
        "    \"O cachorro pregui√ßoso pulou sobre o gato r√°pido.\",\n",
        "\n",
        "    # 4. Totalmente diferente\n",
        "    \"O c√©u est√° azul hoje.\"\n",
        "]\n",
        "\n",
        "# Vamos tokenizar (dividir as palavras) para o BLEU\n",
        "ref_tokenized = [referencia.split()] # BLEU espera uma lista de refer√™ncias\n",
        "cands_tokenized = [c.split() for c in candidatos]\n",
        "\n",
        "# BERTScore usa as senten√ßas brutas (strings)\n",
        "# Precisamos de uma lista de refer√™ncias com o mesmo tamanho da lista de candidatos\n",
        "refs_bert = [referencia] * len(candidatos)"
      ],
      "id": "JH0bW4u1q35c"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0JgTm7uUq35c"
      },
      "outputs": [],
      "source": [
        "# @title 5. C√°lculo das M√©tricas\n",
        "\n",
        "# ----- 5.1. Calcular o BLEU -----\n",
        "# BLEU √© uma m√©trica a n√≠vel de corpus, mas podemos us√°-la\n",
        "# a n√≠vel de senten√ßa com suaviza√ß√£o.\n",
        "scores_bleu = []\n",
        "for cand in cands_tokenized:\n",
        "    score_b = sentence_bleu(ref_tokenized, cand, smoothing_function=chen_smoothing)\n",
        "    scores_bleu.append(score_b)\n",
        "\n",
        "\n",
        "# ----- 5.2. Calcular o BERTScore -----\n",
        "# Usaremos um modelo BERT treinado para o portugu√™s para melhores resultados\n",
        "# lang=\"pt\" automaticamente usa \"neuralmind/bert-base-portuguese-cased\"\n",
        "P, R, F1_bert = score(candidatos, refs_bert, lang=\"pt\", verbose=False)\n",
        "\n",
        "# Vamos extrair apenas o F1-score (a m√©trica principal)\n",
        "scores_bert = F1_bert.tolist()"
      ],
      "id": "0JgTm7uUq35c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "811jDlKtq35d"
      },
      "source": [
        "## 6. An√°lise dos Resultados\n",
        "\n",
        "Vamos colocar tudo em uma tabela para comparar lado a lado.\n",
        "\n",
        "* **Score_BLEU:** Varia de 0.0 a 1.0. Foca na sobreposi√ß√£o de palavras.\n",
        "* **Score_BERT (F1):** Varia (aprox.) de 0.0 a 1.0. Foca na similaridade de significado."
      ],
      "id": "811jDlKtq35d"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtmBniYlq35d",
        "outputId": "06257b73-4f41-4840-c79d-83db4d21cfa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refer√™ncia: O gato r√°pido pulou sobre o cachorro pregui√ßoso.\n",
            "--------------------------------------------------\n",
            "| Candidato                | Senten√ßa                                         |   Score_BLEU |   Score_BERT (F1) |\n",
            "|:-------------------------|:-------------------------------------------------|-------------:|------------------:|\n",
            "| 1. Exato                 | O gato r√°pido pulou sobre o cachorro pregui√ßoso. |       1      |            1      |\n",
            "| 2. Par√°frase (Sin√¥nimos) | O felino √°gil saltou por cima do c√£o sonolento.  |       0.0257 |            0.836  |\n",
            "| 3. Oposto (Sobreposi√ß√£o) | O cachorro pregui√ßoso pulou sobre o gato r√°pido. |       0.1963 |            0.9605 |\n",
            "| 4. Diferente             | O c√©u est√° azul hoje.                            |       0.0251 |            0.6774 |\n"
          ]
        }
      ],
      "source": [
        "# @title 7. Tabela Comparativa\n",
        "\n",
        "data = {\n",
        "    \"Candidato\": [\n",
        "        \"1. Exato\",\n",
        "        \"2. Par√°frase (Sin√¥nimos)\",\n",
        "        \"3. Oposto (Sobreposi√ß√£o)\",\n",
        "        \"4. Diferente\"\n",
        "    ],\n",
        "    \"Senten√ßa\": candidatos,\n",
        "    \"Score_BLEU\": scores_bleu,\n",
        "    \"Score_BERT (F1)\": scores_bert\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Vamos formatar os n√∫meros para melhor leitura\n",
        "df[\"Score_BLEU\"] = df[\"Score_BLEU\"].round(4)\n",
        "df[\"Score_BERT (F1)\"] = df[\"Score_BERT (F1)\"].round(4)\n",
        "\n",
        "print(\"Refer√™ncia:\", referencia)\n",
        "print(\"-\" * 50)\n",
        "print(df.to_markdown(index=False))"
      ],
      "id": "rtmBniYlq35d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHq0dCT2q35e"
      },
      "source": [
        "## 8. Conclus√£o da An√°lise\n",
        "\n",
        "Veja o que a tabela nos mostra:\n",
        "\n",
        "1.  **Candidato 1 (Exato):**\n",
        "    * **BLEU:** 1.00 (Perfeito).\n",
        "    * **BERTScore:** 1.00 (Perfeito).\n",
        "    * *Ambas as m√©tricas concordam que uma correspond√™ncia exata √© perfeita.*\n",
        "\n",
        "2.  **Candidato 2 (Par√°frase/Sin√¥nimos):**\n",
        "    * **BLEU:** ~0.0 (Muito baixo). N√£o h√° quase nenhuma palavra em comum (apenas \"O\" e \"do\").\n",
        "    * **BERTScore:** ~0.84 (Muito alto). O BERT entende que \"gato\" √© sin√¥nimo de \"felino\", \"r√°pido\" de \"√°gil\", \"pulou\" de \"saltou\", etc.\n",
        "    * *Esta √© a maior falha do BLEU e a maior for√ßa do BERTScore.*\n",
        "\n",
        "3.  **Candidato 3 (Oposto):**\n",
        "    * **BLEU:** ~0.20 (M√©dio-Alto). O BLEU v√™ que *todas* as palavras corretas est√£o presentes, ele s√≥ n√£o entende a ordem e, portanto, a mudan√ßa de significado (quem pulou em quem).\n",
        "    * **BERTScore:** ~0.96 (Alto). O BERTScore tamb√©m √© \"enganado\" pela alta sobreposi√ß√£o de palavras, mas geralmente d√° uma pontua√ß√£o ligeiramente menor que uma par√°frase correta, pois o contexto dos embeddings muda.\n",
        "    * *(Nota: A robustez do BERTScore a mudan√ßas de ordem pode variar com o modelo).*\n",
        "\n",
        "4.  **Candidato 4 (Diferente):**\n",
        "    * **BLEU:** ~0.0 (Muito baixo).\n",
        "    * **BERTScore:** ~0.67 (Baixo).\n",
        "    * *Ambas as m√©tricas concordam que esta √© uma p√©ssima correspond√™ncia, mas o BERTScore raramente d√° 0.0, pois sempre h√° alguma similaridade sem√¢ntica residual (palavras como \"O\", \"est√°\", etc.).\n",
        "  "
      ],
      "id": "tHq0dCT2q35e"
    }
  ]
}