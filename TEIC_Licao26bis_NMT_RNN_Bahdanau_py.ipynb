{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsansao/teic-20231/blob/main/TEIC_Licao26bis_NMT_RNN_Bahdanau_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "# ==============================================================================\n",
        "# SCRIPT PYTHON PARA GOOGLE COLAB\n",
        "#\n",
        "# TAREFA: Avaliação de Benchmark de Tradução Automática (NMT)\n",
        "# MODELO: RNN (Seq2Seq com LSTM e ATENÇÃO)\n",
        "# MÉTRICA: BLEU Score\n",
        "#\n",
        "# INSTRUÇÕES:\n",
        "# 1. Abra um novo notebook no Google Colab (https://colab.research.google.com/)\n",
        "# 2. Copie e cole o conteúdo deste arquivo, célula por célula, e execute.\n",
        "#\n",
        "# As seções marcadas com \"# --- CÉLULA X ---\" devem ser coladas\n",
        "# em células separadas do Colab.\n",
        "# ==============================================================================\n",
        "\n",
        "# --- CÉLULA 1: Instalação e Imports ---\n",
        "# (Instala o NLTK para a métrica BLEU e baixa os pacotes necessários)\n",
        "\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "# --- MODIFICADO: Importa AdditiveAttention e Concatenate ---\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, AdditiveAttention, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "print(f\"TensorFlow Versão: {tf.__version__}\")\n",
        "\n",
        "# --- CÉLULA 2: Parâmetros e Download dos Dados ---\n",
        "# (Vamos usar um dataset Português-Inglês do http://www.manythings.org/anki/)\n",
        "\n",
        "#@title Parâmetros do Modelo e Dados\n",
        "NUM_EXEMPLOS = 30000  # Quantidade de frases para treinar. Reduza se o Colab for lento.\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "LATENT_DIM = 256  # Dimensão da camada LSTM\n",
        "\n",
        "# URL do dataset\n",
        "DATA_URL = \"https://github.com/jsansao/transformers_pt/raw/refs/heads/main/por-eng.zip\"\n",
        "DATA_PATH = \"por-eng.zip\"\n",
        "EXTRACT_PATH = \"por-eng\"\n",
        "\n",
        "# Download\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    urllib.request.urlretrieve(DATA_URL, DATA_PATH)\n",
        "    print(\"Dataset baixado.\")\n",
        "\n",
        "# Extração\n",
        "if not os.path.exists(EXTRACT_PATH):\n",
        "    os.makedirs(EXTRACT_PATH)\n",
        "with zipfile.ZipFile(DATA_PATH, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(EXTRACT_PATH)\n",
        "    print(\"Dataset extraído.\")\n",
        "\n",
        "DATA_FILE = os.path.join(EXTRACT_PATH, \"por.txt\")\n",
        "print(f\"Arquivo de dados: {DATA_FILE}\")\n",
        "\n",
        "\n",
        "# --- CÉLULA 3: Carregamento e Pré-processamento ---\n",
        "\n",
        "def preprocess_sentence(s):\n",
        "    \"\"\"\n",
        "    Limpa e prepara uma única sentença.\n",
        "    Adiciona tokens de [start] e [end].\n",
        "    \"\"\"\n",
        "    s = s.lower().strip()\n",
        "    # Adiciona espaço antes da pontuação para tokenização\n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "    s = re.sub(r'[\" \"]+', \" \", s)\n",
        "    # Substitui tudo exceto letras e pontuação básica\n",
        "    s = re.sub(r\"[^a-zA-Záéíóúâêîôûãõç?.!,¿]+\", \" \", s)\n",
        "    s = s.strip()\n",
        "    # Adiciona os tokens de início e fim\n",
        "    s = '[start] ' + s + ' [end]'\n",
        "    return s\n",
        "\n",
        "def load_data(path, num_examples):\n",
        "    \"\"\"\n",
        "    Lê o arquivo .txt e retorna pares de frases (Inglês, Português).\n",
        "    \"\"\"\n",
        "    # O arquivo está no formato: Inglês \\t Português \\t Atribuição\n",
        "    pairs = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f.readlines()[:num_examples]:\n",
        "            parts = line.split('\\t')\n",
        "            # Usamos o Português como ENTRADA (input) e Inglês como SAÍDA (target)\n",
        "            # Você pode inverter se preferir (target_lang, input_lang)\n",
        "            input_text = preprocess_sentence(parts[1])  # Português\n",
        "            target_text = preprocess_sentence(parts[0]) # Inglês\n",
        "            pairs.append((input_text, target_text))\n",
        "\n",
        "    return zip(*pairs)\n",
        "\n",
        "# Carrega os dados\n",
        "input_lang_raw, target_lang_raw = load_data(DATA_FILE, NUM_EXEMPLOS)\n",
        "print(\"Exemplo de dados brutos:\")\n",
        "print(f\"Input (PT): {input_lang_raw[0]}\")\n",
        "print(f\"Target (EN): {target_lang_raw[0]}\")\n",
        "\n",
        "\n",
        "# --- CÉLULA 4: Tokenização e Padding ---\n",
        "# (Transforma as palavras em números (índices) e preenche as sequências)\n",
        "\n",
        "def tokenize(lang):\n",
        "    \"\"\"\n",
        "    Cria um tokenizador Keras para um idioma.\n",
        "    \"\"\"\n",
        "    # oov_token='<unk>' -> Palavras desconhecidas serão mapeadas para <unk>\n",
        "    lang_tokenizer = Tokenizer(filters='', oov_token='<unk>')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    return lang_tokenizer\n",
        "\n",
        "def texts_to_sequences(tokenizer, texts):\n",
        "    \"\"\"\n",
        "    Converte textos em sequências de inteiros.\n",
        "    \"\"\"\n",
        "    return tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Tokeniza o idioma de ENTRADA (Português)\n",
        "input_tokenizer = tokenize(input_lang_raw)\n",
        "input_tensor = texts_to_sequences(input_tokenizer, input_lang_raw)\n",
        "input_tensor = pad_sequences(input_tensor, padding='post')\n",
        "\n",
        "# Tokeniza o idioma ALVO (Inglês)\n",
        "target_tokenizer = tokenize(target_lang_raw)\n",
        "target_tensor = texts_to_sequences(target_tokenizer, target_lang_raw)\n",
        "target_tensor = pad_sequences(target_tensor, padding='post')\n",
        "\n",
        "# Índices (Word -> ID) e Índices Inversos (ID -> Word)\n",
        "input_word_index = input_tokenizer.word_index\n",
        "input_index_word = input_tokenizer.index_word\n",
        "target_word_index = target_tokenizer.word_index\n",
        "target_index_word = target_tokenizer.index_word\n",
        "\n",
        "# Tamanho dos vocabulários (adiciona 1 para o token 0 de padding)\n",
        "VOCAB_SIZE_INPUT = len(input_word_index) + 1\n",
        "VOCAB_SIZE_TARGET = len(target_word_index) + 1\n",
        "\n",
        "# Tamanho máximo das sequências\n",
        "MAX_LEN_INPUT = input_tensor.shape[1]\n",
        "MAX_LEN_TARGET = target_tensor.shape[1]\n",
        "\n",
        "print(\"\\n--- Estatísticas dos Dados ---\")\n",
        "print(f\"Frases de entrada (PT): {len(input_tensor)}\")\n",
        "print(f\"Frases de saída (EN): {len(target_tensor)}\")\n",
        "print(f\"Tamanho Vocabulário PT: {VOCAB_SIZE_INPUT}\")\n",
        "print(f\"Tamanho Vocabulário EN: {VOCAB_SIZE_TARGET}\")\n",
        "print(f\"Tamanho Máx. Sequência PT: {MAX_LEN_INPUT}\")\n",
        "print(f\"Tamanho Máx. Sequência EN: {MAX_LEN_TARGET}\")\n",
        "\n",
        "# --- CÉLULA 5: Preparação dos Dados para Treinamento (Teacher Forcing) ---\n",
        "# (O modelo Seq2Seq precisa de 3 partes: entrada do encoder, entrada do decoder e saída do decoder)\n",
        "\n",
        "# 1. encoder_input_data: A frase em Português\n",
        "encoder_input_data = input_tensor\n",
        "\n",
        "# 2. decoder_input_data: A frase em Inglês, \"deslocada\"\n",
        "#    (Ex: \"[start] a cat sat [end]\" -> \"[start] a cat sat\")\n",
        "#    Isso é o \"teacher forcing\".\n",
        "decoder_input_data = target_tensor[:, :-1]\n",
        "\n",
        "# 3. decoder_target_data: A frase em Inglês, \"deslocada\" para o alvo\n",
        "#    (Ex: \"[start] a cat sat [end]\" -> \"a cat sat [end]\")\n",
        "#    O modelo tenta prever esta sequência.\n",
        "decoder_target_data = target_tensor[:, 1:]\n",
        "\n",
        "# Ajusta a forma do target para a loss function\n",
        "decoder_target_data = np.expand_dims(decoder_target_data, -1)\n",
        "\n",
        "print(\"\\n--- Formas dos Dados de Treinamento ---\")\n",
        "print(f\"Encoder Input (PT): {encoder_input_data.shape}\")\n",
        "print(f\"Decoder Input (EN - Teacher Forcing): {decoder_input_data.shape}\")\n",
        "print(f\"Decoder Target (EN - Labels): {decoder_target_data.shape}\")\n",
        "\n",
        "# Cria um tf.data.Dataset para eficiência\n",
        "BUFFER_SIZE = len(input_tensor)\n",
        "# Modify the dataset creation to yield inputs as a tuple in the correct order\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((encoder_input_data, decoder_input_data), decoder_target_data))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Separa 10% para validação/benchmark\n",
        "validation_size = int(0.1 * len(input_tensor))\n",
        "train_size = len(input_tensor) - validation_size\n",
        "\n",
        "# Pega os dados de validação ANTES de embaralhar o dataset\n",
        "# (Usaremos esses dados crus para o benchmark BLEU)\n",
        "validation_inputs_raw = input_lang_raw[train_size:]\n",
        "validation_targets_raw = target_lang_raw[train_size:]\n",
        "\n",
        "# Pega os tensores de validação\n",
        "validation_encoder_input = encoder_input_data[train_size:]\n",
        "# (Não precisamos dos outros para a inferência)\n",
        "\n",
        "print(f\"\\nTamanho Treino: {train_size}\")\n",
        "print(f\"Tamanho Validação (Benchmark): {validation_size}\")\n",
        "\n",
        "# --- CÉLULA 6: Definição do Modelo Seq2Seq (RNN/LSTM) com ATENÇÃO ---\n",
        "# (Este é o modelo de *treinamento* que usa teacher forcing)\n",
        "\n",
        "# --- ENCODER (Codificador) ---\n",
        "# Recebe a sequência de entrada (PT)\n",
        "encoder_inputs = Input(shape=(MAX_LEN_INPUT,), name=\"encoder_input\")\n",
        "# Camada de Embedding (transforma IDs em vetores densos)\n",
        "encoder_embedding = Embedding(VOCAB_SIZE_INPUT, LATENT_DIM, name=\"encoder_embedding\")(encoder_inputs)\n",
        "# Camada de LSTM (o \"RNN\")\n",
        "# --- MODIFICADO: return_sequences=True para retornar a saída de todos os passos ---\n",
        "encoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name=\"encoder_lstm\")\n",
        "# Agora pegamos as saídas (outputs) e os estados\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "# Agrupamos os estados (hidden state e cell state)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# --- DECODER (Decodificador) ---\n",
        "# Recebe a sequência alvo (EN) para o teacher forcing\n",
        "decoder_inputs = Input(shape=(MAX_LEN_TARGET - 1,), name=\"decoder_input\") # (Lembre-se que removemos o último token)\n",
        "# Camada de Embedding (compartilhar pesos é avançado, aqui usamos separado)\n",
        "decoder_embedding_layer = Embedding(VOCAB_SIZE_TARGET, LATENT_DIM, name=\"decoder_embedding\")\n",
        "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "# Camada LSTM do Decoder\n",
        "# return_sequences=True faz o LSTM retornar a sequência completa de saídas\n",
        "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "# IMPORTANTE: Inicializamos o estado do Decoder com os estados finais do Encoder\n",
        "decoder_lstm_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# --- INÍCIO DA CAMADA DE ATENÇÃO (MODIFICADO) ---\n",
        "# Usamos AdditiveAttention (estilo Bahdanau)\n",
        "# A camada de atenção irá calcular um \"vetor de contexto\"\n",
        "# Query = O estado atual do decoder (decoder_lstm_outputs)\n",
        "# Value = Todas as saídas do encoder (encoder_outputs)\n",
        "attention_layer = AdditiveAttention(name=\"attention_layer\")\n",
        "context_vector = attention_layer([decoder_lstm_outputs, encoder_outputs])\n",
        "\n",
        "# Concatenamos a saída do LSTM do decoder com o vetor de contexto\n",
        "# Isso dá ao decoder informações sobre qual palavra de entrada focar\n",
        "decoder_concat_input = Concatenate(axis=-1, name=\"concat_layer\")([decoder_lstm_outputs, context_vector])\n",
        "# --- FIM DA CAMADA DE ATENÇÃO ---\n",
        "\n",
        "# Camada Densa final para classificação sobre o vocabulário alvo\n",
        "# --- MODIFICADO: Usa o vetor concatenado (decoder_concat_input) ---\n",
        "decoder_dense = Dense(VOCAB_SIZE_TARGET, activation='softmax', name=\"decoder_dense\")\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# --- MODELO COMPLETO (Treinamento) ---\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compila o modelo\n",
        "# Usamos 'sparse_categorical_crossentropy' porque nossos alvos (decoder_target_data) são inteiros, não one-hot.\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- CÉLULA 7: Treinamento do Modelo ---\n",
        "# (Isso pode levar alguns minutos no Colab)\n",
        "\n",
        "print(\"\\nIniciando o treinamento...\")\n",
        "history = model.fit(dataset.take(train_size // BATCH_SIZE),\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=dataset.skip(train_size // BATCH_SIZE),\n",
        "                    verbose=1)\n",
        "print(\"Treinamento concluído.\")\n",
        "\n",
        "\n",
        "# --- CÉLULA 8: Definição dos Modelos de Inferência (Tradução) com ATENÇÃO ---\n",
        "# (Para traduzir, precisamos de um modelo diferente que gere palavra por palavra)\n",
        "\n",
        "# O processo de tradução (inferência) é diferente do treinamento.\n",
        "# 1. Codificamos a frase de entrada (PT) e obtemos os estados [state_h, state_c].\n",
        "# 2. Alimentamos o decoder com o token [start] e os estados do encoder.\n",
        "# 3. O decoder prevê a próxima palavra (ex: \"a\").\n",
        "# 4. Alimentamos o decoder com a palavra \"a\" e os *novos* estados internos do decoder.\n",
        "# 5. Repetimos até o decoder prever [end] ou atingir o limite de tamanho.\n",
        "\n",
        "# --- 1. Modelo Encoder de Inferência ---\n",
        "# --- MODIFICADO: Agora retorna as SAÍDAS (encoder_outputs) E os estados ---\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_states])\n",
        "\n",
        "# --- 2. Modelo Decoder de Inferência ---\n",
        "# (Pega o token anterior, os estados anteriores E a saída completa do encoder,\n",
        "#  e retorna o novo token e novos estados)\n",
        "\n",
        "# --- MODIFICADO: Novo Input para as saídas do encoder ---\n",
        "# Este input receberá a sequência completa de saídas do encoder\n",
        "encoder_output_sequence_input = Input(shape=(MAX_LEN_INPUT, LATENT_DIM), name=\"encoder_output_seq\")\n",
        "\n",
        "# Inputs de estado para o decoder (iguais)\n",
        "decoder_state_h_input = Input(shape=(LATENT_DIM,))\n",
        "decoder_state_c_input = Input(shape=(LATENT_DIM,))\n",
        "decoder_states_inputs = [decoder_state_h_input, decoder_state_c_input]\n",
        "\n",
        "# Input para o token (agora com tamanho 1) (igual)\n",
        "decoder_single_input = Input(shape=(1,))\n",
        "\n",
        "# Reutilizamos as camadas de embedding e LSTM do modelo treinado\n",
        "decoder_embedding_inference = decoder_embedding_layer(decoder_single_input)\n",
        "# Executa um passo do decoder\n",
        "decoder_outputs_inference, state_h_inf, state_c_inf = decoder_lstm(\n",
        "    decoder_embedding_inference, initial_state=decoder_states_inputs)\n",
        "decoder_states_inference = [state_h_inf, state_c_inf]\n",
        "\n",
        "# --- MODIFICADO: Aplica a Atenção na Inferência ---\n",
        "# A query é a saída do decoder neste passo (decoder_outputs_inference)\n",
        "# O value é a saída completa do encoder (encoder_output_sequence_input)\n",
        "context_vector_inf = attention_layer([decoder_outputs_inference, encoder_output_sequence_input])\n",
        "# Concatena a saída do decoder e o contexto\n",
        "decoder_concat_inf = Concatenate(axis=-1)([decoder_outputs_inference, context_vector_inf])\n",
        "\n",
        "# --- MODIFICADO: A camada Densa usa o vetor concatenado ---\n",
        "decoder_outputs_inference = decoder_dense(decoder_concat_inf)\n",
        "\n",
        "# O modelo final do decoder\n",
        "# --- MODIFICADO: O modelo agora aceita mais um input (encoder_output_sequence_input) ---\n",
        "decoder_model = Model(\n",
        "    [decoder_single_input, encoder_output_sequence_input] + decoder_states_inputs,\n",
        "    [decoder_outputs_inference] + decoder_states_inference\n",
        ")\n",
        "\n",
        "print(\"\\nModelos de inferência (encoder e decoder) com ATENÇÃO criados.\")\n",
        "encoder_model.summary()\n",
        "decoder_model.summary()\n",
        "\n",
        "\n",
        "# --- CÉLULA 9: Função de Tradução (Inferência) com ATENÇÃO ---\n",
        "\n",
        "def translate_sentence(input_seq):\n",
        "    \"\"\"\n",
        "    Traduz uma única sequência (pré-processada) usando os modelos de inferência\n",
        "    com ATENÇÃO.\n",
        "    \"\"\"\n",
        "    # 1. Obtém os estados E AS SAÍDAS do encoder\n",
        "    # --- MODIFICADO: encoder_model agora retorna (encoder_outputs, states) ---\n",
        "    encoder_outputs_val, states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # 2. Prepara o input inicial do decoder (o token [start])\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_word_index['[start]']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "\n",
        "    while not stop_condition:\n",
        "        # 3. Prediz a próxima palavra\n",
        "        # --- MODIFICADO: Passa a saída do encoder (encoder_outputs_val) para a atenção ---\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs_val] + states_value, verbose=0)\n",
        "\n",
        "        # 4. Obtém o ID da palavra prevista (a mais provável)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = target_index_word[sampled_token_index]\n",
        "\n",
        "        # 5. Adiciona a palavra à sentença (if not [end])\n",
        "        if sampled_word == '[end]':\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence.append(sampled_word)\n",
        "\n",
        "        # 6. Check for stop condition\n",
        "        if stop_condition or len(decoded_sentence) > MAX_LEN_TARGET:\n",
        "            stop_condition = True\n",
        "\n",
        "        # 7. Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 8. Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(decoded_sentence)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Versão: 2.19.0\n",
            "Dataset baixado.\n",
            "Dataset extraído.\n",
            "Arquivo de dados: por-eng/por.txt\n",
            "Exemplo de dados brutos:\n",
            "Input (PT): [start] vai . [end]\n",
            "Target (EN): [start] go . [end]\n",
            "\n",
            "--- Estatísticas dos Dados ---\n",
            "Frases de entrada (PT): 30000\n",
            "Frases de saída (EN): 30000\n",
            "Tamanho Vocabulário PT: 7206\n",
            "Tamanho Vocabulário EN: 4168\n",
            "Tamanho Máx. Sequência PT: 14\n",
            "Tamanho Máx. Sequência EN: 10\n",
            "\n",
            "--- Formas dos Dados de Treinamento ---\n",
            "Encoder Input (PT): (30000, 14)\n",
            "Decoder Input (EN - Teacher Forcing): (30000, 9)\n",
            "Decoder Target (EN - Labels): (30000, 9, 1)\n",
            "\n",
            "Tamanho Treino: 27000\n",
            "Tamanho Validação (Benchmark): 3000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,844,736\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │  \u001b[38;5;34m1,067,008\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ encoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ decoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m4168\u001b[0m)   │  \u001b[38;5;34m2,138,184\u001b[0m │ concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,844,736</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,067,008</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ encoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ decoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4168</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,184</span> │ concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,100,808\u001b[0m (23.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,100,808</span> (23.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,100,808\u001b[0m (23.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,100,808</span> (23.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento...\n",
            "Epoch 1/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.5595 - loss: 3.0671 - val_accuracy: 0.6999 - val_loss: 1.7429\n",
            "Epoch 2/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.7294 - loss: 1.5812 - val_accuracy: 0.7840 - val_loss: 1.1670\n",
            "Epoch 3/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.7933 - loss: 1.1141 - val_accuracy: 0.8315 - val_loss: 0.8196\n",
            "Epoch 4/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.8386 - loss: 0.7876 - val_accuracy: 0.8767 - val_loss: 0.5705\n",
            "Epoch 5/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8796 - loss: 0.5488 - val_accuracy: 0.9140 - val_loss: 0.3822\n",
            "Epoch 6/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9122 - loss: 0.3857 - val_accuracy: 0.9386 - val_loss: 0.2694\n",
            "Epoch 7/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9345 - loss: 0.2777 - val_accuracy: 0.9502 - val_loss: 0.2105\n",
            "Epoch 8/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9493 - loss: 0.2108 - val_accuracy: 0.9603 - val_loss: 0.1660\n",
            "Epoch 9/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9588 - loss: 0.1636 - val_accuracy: 0.9668 - val_loss: 0.1301\n",
            "Epoch 10/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9661 - loss: 0.1339 - val_accuracy: 0.9736 - val_loss: 0.1055\n",
            "Epoch 11/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9709 - loss: 0.1120 - val_accuracy: 0.9756 - val_loss: 0.0934\n",
            "Epoch 12/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9734 - loss: 0.1000 - val_accuracy: 0.9792 - val_loss: 0.0818\n",
            "Epoch 13/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9766 - loss: 0.0859 - val_accuracy: 0.9821 - val_loss: 0.0697\n",
            "Epoch 14/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.9784 - loss: 0.0779 - val_accuracy: 0.9811 - val_loss: 0.0670\n",
            "Epoch 15/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9791 - loss: 0.0731 - val_accuracy: 0.9822 - val_loss: 0.0616\n",
            "Epoch 16/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9813 - loss: 0.0641 - val_accuracy: 0.9832 - val_loss: 0.0551\n",
            "Epoch 17/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9816 - loss: 0.0610 - val_accuracy: 0.9845 - val_loss: 0.0530\n",
            "Epoch 18/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9822 - loss: 0.0582 - val_accuracy: 0.9846 - val_loss: 0.0511\n",
            "Epoch 19/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9828 - loss: 0.0557 - val_accuracy: 0.9842 - val_loss: 0.0503\n",
            "Epoch 20/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.9832 - loss: 0.0535 - val_accuracy: 0.9850 - val_loss: 0.0463\n",
            "Epoch 21/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9839 - loss: 0.0501 - val_accuracy: 0.9850 - val_loss: 0.0481\n",
            "Epoch 22/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9842 - loss: 0.0489 - val_accuracy: 0.9867 - val_loss: 0.0427\n",
            "Epoch 23/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9843 - loss: 0.0476 - val_accuracy: 0.9861 - val_loss: 0.0430\n",
            "Epoch 24/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9848 - loss: 0.0458 - val_accuracy: 0.9871 - val_loss: 0.0402\n",
            "Epoch 25/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.9847 - loss: 0.0464 - val_accuracy: 0.9864 - val_loss: 0.0420\n",
            "Epoch 26/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.9851 - loss: 0.0445 - val_accuracy: 0.9876 - val_loss: 0.0370\n",
            "Epoch 27/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9851 - loss: 0.0441 - val_accuracy: 0.9865 - val_loss: 0.0400\n",
            "Epoch 28/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9853 - loss: 0.0436 - val_accuracy: 0.9867 - val_loss: 0.0395\n",
            "Epoch 29/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.9857 - loss: 0.0426 - val_accuracy: 0.9871 - val_loss: 0.0369\n",
            "Epoch 30/30\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9859 - loss: 0.0406 - val_accuracy: 0.9869 - val_loss: 0.0385\n",
            "Treinamento concluído.\n",
            "\n",
            "Modelos de inferência (encoder e decoder) com ATENÇÃO criados.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_embedding (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m1,844,736\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │               │\n",
              "│                                 │ \u001b[38;5;34m256\u001b[0m)]                  │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,844,736</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │               │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,370,048\u001b[0m (9.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,370,048</span> (9.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,370,048\u001b[0m (9.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,370,048</span> (9.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │  \u001b[38;5;34m1,067,008\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ decoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_output_seq  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ decoder_lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ encoder_output_s… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ decoder_lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4168\u001b[0m)   │  \u001b[38;5;34m2,138,184\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,067,008</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ decoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_output_seq  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ encoder_output_s… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4168</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,184</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,730,760\u001b[0m (14.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,730,760</span> (14.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,730,760\u001b[0m (14.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,730,760</span> (14.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tWi9dved7fFJ",
        "outputId": "7b9c3446-8018-494e-893a-9e0c238e2930"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CÉLULA 10: Avaliação do Benchmark (BLEU Score) ---\n",
        "# (Calculamos a métrica BLEU no conjunto de validação)\n",
        "\n",
        "print(\"\\n--- Iniciando Avaliação do Benchmark (BLEU Score) ---\")\n",
        "\n",
        "references = [] # The real translations (gold)\n",
        "predictions = [] # The model's translations (hypotheses)\n",
        "\n",
        "# Iterate over the validation set (benchmark)\n",
        "# (Use .iloc to ensure we are getting the correct data)\n",
        "\n",
        "for i in range(len(validation_encoder_input)):\n",
        "\n",
        "    input_seq = validation_encoder_input[i:i+1] # Get the input sequence\n",
        "\n",
        "    # Translate the sequence\n",
        "    predicted_sentence = translate_sentence(input_seq)\n",
        "\n",
        "    # Get the real target sentence (reference)\n",
        "    # Remove [start] and [end] from the reference for BLEU calculation\n",
        "    reference_sentence_raw = validation_targets_raw[i]\n",
        "    reference_sentence = reference_sentence_raw.replace('[start] ', '').replace(' [end]', '')\n",
        "\n",
        "    # NLTK expects lists of words\n",
        "    references.append([reference_sentence.split()]) # BLEU can have multiple refs, hence [[]]\n",
        "    predictions.append(predicted_sentence.split())\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Evaluating {i}/{len(validation_encoder_input)}...\")\n",
        "        print(f\"  Input (PT): {validation_inputs_raw[i]}\")\n",
        "        print(f\"  Real (EN): {reference_sentence}\")\n",
        "        print(f\"  Prev (EN): {predicted_sentence}\")\n",
        "\n",
        "# --- FINAL BLEU CALCULATION ---\n",
        "# BLEU-1 (unigrams)\n",
        "bleu_1 = corpus_bleu(references, predictions, weights=(1, 0, 0, 0))\n",
        "# BLEU-4 (standard)\n",
        "bleu_4 = corpus_bleu(references, predictions, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"\\n--- BENCHMARK RESULT ---\")\n",
        "print(f\"Total sentences evaluated: {len(references)}\")\n",
        "print(f\"BLEU-1 Score (Unigrams): {bleu_1 * 100:.2f}\")\n",
        "print(f\"BLEU-4 Score (Corpus): {bleu_4 * 100:.2f}\")\n"
      ],
      "metadata": {
        "id": "swURhuszHmDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a02056-3ee7-4188-b5f6-6b5f62bf88a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Avaliação do Benchmark (BLEU Score) ---\n",
            "Evaluating 0/3000...\n",
            "  Input (PT): [start] tu és inflexível . [end]\n",
            "  Real (EN): you re inflexible .\n",
            "  Prev (EN): you re inflexible .\n",
            "Evaluating 100/3000...\n",
            "  Input (PT): [start] todos nós conhecemos tom . [end]\n",
            "  Real (EN): all of us know tom .\n",
            "  Prev (EN): all of us know tom .\n",
            "Evaluating 200/3000...\n",
            "  Input (PT): [start] você é o médico ? [end]\n",
            "  Real (EN): are you the doctor ?\n",
            "  Prev (EN): are you the doctor ?\n",
            "Evaluating 300/3000...\n",
            "  Input (PT): [start] cheque aquele carro . [end]\n",
            "  Real (EN): check out that car .\n",
            "  Prev (EN): check that car out .\n",
            "Evaluating 400/3000...\n",
            "  Input (PT): [start] você tem o bastante ? [end]\n",
            "  Real (EN): do you have enough ?\n",
            "  Prev (EN): do you have enough ?\n",
            "Evaluating 500/3000...\n",
            "  Input (PT): [start] será que o gosto é bom ? [end]\n",
            "  Real (EN): does it taste good ?\n",
            "  Prev (EN): does it taste good ?\n",
            "Evaluating 600/3000...\n",
            "  Input (PT): [start] não escreva a tinta . [end]\n",
            "  Real (EN): don t write in ink .\n",
            "  Prev (EN): don t write in ink .\n",
            "Evaluating 700/3000...\n",
            "  Input (PT): [start] vai embora daqui . [end]\n",
            "  Real (EN): get away from here .\n",
            "  Prev (EN): get away from here .\n",
            "Evaluating 800/3000...\n",
            "  Input (PT): [start] ela sabe dirigir carro . [end]\n",
            "  Real (EN): he can drive a car .\n",
            "  Prev (EN): he can drive a car .\n",
            "Evaluating 900/3000...\n",
            "  Input (PT): [start] ele mora aqui perto . [end]\n",
            "  Real (EN): he lives near here .\n",
            "  Prev (EN): he lives near here .\n",
            "Evaluating 1000/3000...\n",
            "  Input (PT): [start] aqui está seu troco . [end]\n",
            "  Real (EN): here s your change .\n",
            "  Prev (EN): here s your change .\n",
            "Evaluating 1100/3000...\n",
            "  Input (PT): [start] já o fiz . [end]\n",
            "  Real (EN): i already did that .\n",
            "  Prev (EN): i already did it .\n",
            "Evaluating 1200/3000...\n",
            "  Input (PT): [start] posso esperá lo . [end]\n",
            "  Real (EN): i can wait for you .\n",
            "  Prev (EN): i can wait for you .\n",
            "Evaluating 1300/3000...\n",
            "  Input (PT): [start] eu não queria isso . [end]\n",
            "  Real (EN): i didn t want this .\n",
            "  Prev (EN): i didn t want that .\n",
            "Evaluating 1400/3000...\n",
            "  Input (PT): [start] eu sigo as regras . [end]\n",
            "  Real (EN): i follow the rules .\n",
            "  Prev (EN): i follow the rules .\n",
            "Evaluating 1500/3000...\n",
            "  Input (PT): [start] eu não tenho religião . [end]\n",
            "  Real (EN): i have no religion .\n",
            "  Prev (EN): i have no religion .\n",
            "Evaluating 1600/3000...\n",
            "  Input (PT): [start] eu beijei tom de novo . [end]\n",
            "  Real (EN): i kissed tom again .\n",
            "  Prev (EN): i kissed tom again .\n",
            "Evaluating 1700/3000...\n",
            "  Input (PT): [start] eu gosto de matemática . [end]\n",
            "  Real (EN): i like mathematics .\n",
            "  Prev (EN): i like math .\n",
            "Evaluating 1800/3000...\n",
            "  Input (PT): [start] eu me mudei mês passado . [end]\n",
            "  Real (EN): i moved last month .\n",
            "  Prev (EN): i moved last month .\n",
            "Evaluating 1900/3000...\n",
            "  Input (PT): [start] eu me lembro também . [end]\n",
            "  Real (EN): i remember it , too .\n",
            "  Prev (EN): i remember it , too .\n",
            "Evaluating 2000/3000...\n",
            "  Input (PT): [start] eu acho que você vai ganhar . [end]\n",
            "  Real (EN): i think you ll win .\n",
            "  Prev (EN): i think you ll win .\n",
            "Evaluating 2100/3000...\n",
            "  Input (PT): [start] quero que você cante . [end]\n",
            "  Real (EN): i want you to sing .\n",
            "  Prev (EN): i want you to sing .\n",
            "Evaluating 2200/3000...\n",
            "  Input (PT): [start] não te assistirei . [end]\n",
            "  Real (EN): i won t assist you .\n",
            "  Prev (EN): i won t assist you .\n",
            "Evaluating 2300/3000...\n",
            "  Input (PT): [start] irei parar mais tarde . [end]\n",
            "  Real (EN): i ll stop by later .\n",
            "  Prev (EN): i ll stop by later .\n",
            "Evaluating 2400/3000...\n",
            "  Input (PT): [start] estou melhor . [end]\n",
            "  Real (EN): i m feeling better .\n",
            "  Prev (EN): i m better .\n",
            "Evaluating 2500/3000...\n",
            "  Input (PT): [start] eu não estou com raiva do tom . [end]\n",
            "  Real (EN): i m not mad at tom .\n",
            "  Prev (EN): i m not mad at tom .\n",
            "Evaluating 2600/3000...\n",
            "  Input (PT): [start] estou muito feliz agora . [end]\n",
            "  Real (EN): i m very happy now .\n",
            "  Prev (EN): i m very happy now .\n",
            "Evaluating 2700/3000...\n",
            "  Input (PT): [start] ela também vem ? [end]\n",
            "  Real (EN): is she coming , too ?\n",
            "  Prev (EN): is she coming , too ?\n",
            "Evaluating 2800/3000...\n",
            "  Input (PT): [start] não é nada fácil . [end]\n",
            "  Real (EN): it isn t very easy .\n",
            "  Prev (EN): it isn t very easy .\n",
            "Evaluating 2900/3000...\n",
            "  Input (PT): [start] ficará tudo bem . [end]\n",
            "  Real (EN): it ll be all right .\n",
            "  Prev (EN): it ll be all right .\n",
            "\n",
            "--- BENCHMARK RESULT ---\n",
            "Total sentences evaluated: 3000\n",
            "BLEU-1 Score (Unigrams): 98.06\n",
            "BLEU-4 Score (Corpus): 95.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Manual Test ---\")\n",
        "# Pick a random sentence from the validation set\n",
        "idx = np.random.randint(0, len(validation_encoder_input))\n",
        "\n",
        "input_seq_test = validation_encoder_input[idx:idx+1]\n",
        "input_raw_test = validation_inputs_raw[idx]\n",
        "target_raw_test = validation_targets_raw[idx].replace('[start] ', '').replace(' [end]', '')\n",
        "predicted_test = translate_sentence(input_seq_test)\n",
        "\n",
        "print(f\"Input Sentence (PT): {input_raw_test}\")\n",
        "print(f\"Real Translation (EN):    {target_raw_test}\")\n",
        "print(f\"Model Translation (EN): {predicted_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spj8MhkePPQ7",
        "outputId": "2dc00555-8137-4d16-8d2c-81233b8b8e13"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Manual Test ---\n",
            "Input Sentence (PT): [start] eu acho que gosto de você . [end]\n",
            "Real Translation (EN):    i think i like you .\n",
            "Model Translation (EN): i think i like you .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CÉLULA 11: Função para Traduzir uma String Arbitrária ---\n",
        "# (Usa as funções de pré-processamento e inferência definidas anteriormente)\n",
        "\n",
        "def translate_string(input_string):\n",
        "    \"\"\"\n",
        "    Traduz uma string de texto em Português para Inglês.\n",
        "    \"\"\"\n",
        "    # 1. Pré-processa a string de entrada\n",
        "    processed_string = preprocess_sentence(input_string)\n",
        "\n",
        "    # 2. Converte a string processada para uma sequência de IDs\n",
        "    # O tokenizer espera uma lista de strings\n",
        "    input_seq = texts_to_sequences(input_tokenizer, [processed_string])\n",
        "    # Garante o padding correto\n",
        "    input_seq = pad_sequences(input_seq, maxlen=MAX_LEN_INPUT, padding='post')\n",
        "\n",
        "    # 3. Chama a função de inferência para traduzir a sequência\n",
        "    translated_sentence = translate_sentence(input_seq)\n",
        "\n",
        "    return translated_sentence\n",
        "\n",
        "# --- Exemplo de uso ---\n",
        "test_string = \"Olá, como você está?\"\n",
        "translated_string = translate_string(test_string)\n",
        "print(f\"\\nOriginal (PT): {test_string}\")\n",
        "print(f\"Traduzido (EN): {translated_string}\")\n",
        "\n",
        "test_string_2 = \"Eu estou esperando.\"\n",
        "translated_string_2 = translate_string(test_string_2)\n",
        "print(f\"\\nOriginal (PT): {test_string_2}\")\n",
        "print(f\"Traduzido (EN): {translated_string_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8B1IbgzaXQE",
        "outputId": "c70d1878-1ac4-4469-c7a0-ab26a75040d8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original (PT): Olá, como você está?\n",
            "Traduzido (EN): hello , how are you ?\n",
            "\n",
            "Original (PT): Eu estou esperando.\n",
            "Traduzido (EN): i m waiting .\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}