{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsansao/teic-20231/blob/main/TEIC_Licao21_Word2VecLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ3jDU8IxAEq"
      },
      "source": [
        "# Classificação de Texto com Word2Vec (Gensim) e LSTM (Keras)\n",
        "\n",
        "Este notebook demonstra uma abordagem de \"Transfer Learning\" para NLP. Em vez de treinar uma camada de Embedding do zero, vamos usar vetores de palavras (word embeddings) pré-treinados com o algoritmo **Word2Vec**.\n",
        "\n",
        "O fluxo será:\n",
        "1. Carregar e pré-processar os dados de texto.\n",
        "2. Treinar nosso próprio modelo Word2Vec (via `gensim`) nos textos.\n",
        "3. Preparar os textos para o Keras (Tokenização e Padding).\n",
        "4. Criar uma Matriz de Embedding que \"injeta\" os vetores do Word2Vec no Keras.\n",
        "5. Construir, treinar e avaliar um modelo LSTM que utiliza esses embeddings congelados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSX_46f_xAE2",
        "outputId": "2d31b8a0-5741-446b-c873-fd8978f81385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "# Célula 1: Instalação e Importações\n",
        "\n",
        "# O Gensim é a biblioteca padrão para modelagem de tópicos e Word2Vec\n",
        "!pip install gensim\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# Suprimir avisos\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFJumdyIxAE9"
      },
      "source": [
        "## Passo 1: Carregar e Preparar Dados\n",
        "\n",
        "Primeiro, carregamos o mesmo conjunto de dados (20 Newsgroups, 2 categorias) da comparação anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK-HWlH7xAFB",
        "outputId": "6c456fef-20d1-4b18-f35a-7f71b9651cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras de treino: 1571\n",
            "Amostras de teste: 393\n"
          ]
        }
      ],
      "source": [
        "# Célula 2: Carregar os dados\n",
        "categorias = ['comp.graphics', 'sci.crypt']\n",
        "dados = fetch_20newsgroups(subset='all', categories=categorias, shuffle=True, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Separar dados e rótulos\n",
        "textos = dados.data\n",
        "rotulos = dados.target # 0 para 'comp.graphics', 1 para 'sci.crypt'\n",
        "\n",
        "# Dividir em treino e teste\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(textos, rotulos, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Amostras de treino: {len(X_train_text)}\")\n",
        "print(f\"Amostras de teste: {len(X_test_text)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5UsWZ_AxAFJ"
      },
      "source": [
        "## Passo 2: Treinar o Modelo Word2Vec (Gensim)\n",
        "\n",
        "Para treinar o Word2Vec, precisamos de sentenças tokenizadas (listas de palavras). Vamos fazer um pré-processamento simples (remover não-alfanuméricos, passar para minúsculas) e treinar o modelo em **todos** os textos (treino e teste), pois o Word2Vec é um aprendizado não supervisionado e se beneficia de mais dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqyimSOMxAFN",
        "outputId": "042da168-4da7-41bc-befd-b618f3b04e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeiro documento tokenizado (para Gensim):\n",
            "[]...\n"
          ]
        }
      ],
      "source": [
        "# Célula 3: Pré-processamento para o Gensim\n",
        "\n",
        "def preprocess_text_gensim(text):\n",
        "    text = re.sub(r'\\W+', ' ', text) # Remove caracteres não-alfanuméricos\n",
        "    text = text.lower()\n",
        "    return text.split() # Retorna uma lista de palavras (tokens)\n",
        "\n",
        "# Processar todos os textos (treino + teste)\n",
        "textos_completos = X_train_text + X_test_text\n",
        "textos_tokenizados = [preprocess_text_gensim(doc) for doc in textos_completos]\n",
        "\n",
        "print(f\"Primeiro documento tokenizado (para Gensim):\\n{textos_tokenizados[0][:20]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ8_l3rOxAFR",
        "outputId": "6d756eb6-aeef-4c5b-fe36-4d79c4805990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando modelo Word2Vec...\n",
            "Treino do Word2Vec concluído.\n",
            "Tamanho do vocabulário do Word2Vec (com min_count=3): 9871 palavras\n",
            "\n",
            "Palavras mais similares a 'computer':\n",
            "[('visualisation', 0.9082591533660889), ('research', 0.8919011354446411), ('symposium', 0.8791888356208801), ('aided', 0.875365674495697), ('primitives', 0.8682764172554016), ('atmospheric', 0.8668799996376038), ('systems', 0.8644639849662781), ('itti', 0.8635594248771667), ('visualization', 0.8622421026229858), ('national', 0.8614664077758789)]\n",
            "\n",
            "Palavras mais similares a 'crypto':\n",
            "[('strong', 0.9829712510108948), ('being', 0.9718181490898132), ('classified', 0.9706794023513794), ('legal', 0.9664202332496643), ('clinton', 0.9659008979797363), ('door', 0.9649192094802856), ('phones', 0.9636639356613159), ('cripple', 0.9628631472587585), ('fact', 0.9614049792289734), ('illegal', 0.9572980403900146)]\n"
          ]
        }
      ],
      "source": [
        "# Célula 4: Treinar o modelo Word2Vec\n",
        "\n",
        "# Parâmetros do Word2Vec\n",
        "DIM_EMBEDDING = 100    # Dimensão dos vetores de palavras\n",
        "WINDOW_SIZE = 5      # Tamanho da janela de contexto\n",
        "MIN_COUNT = 3        # Ignorar palavras com frequência menor que esta\n",
        "WORKERS = 4          # Threads para paralelizar o treino\n",
        "\n",
        "print(\"Treinando modelo Word2Vec...\")\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=textos_tokenizados,\n",
        "    vector_size=DIM_EMBEDDING,\n",
        "    window=WINDOW_SIZE,\n",
        "    min_count=MIN_COUNT,\n",
        "    workers=WORKERS\n",
        ")\n",
        "\n",
        "print(\"Treino do Word2Vec concluído.\")\n",
        "\n",
        "# Verificar o vocabulário aprendido\n",
        "vocab_size_w2v = len(w2v_model.wv.key_to_index)\n",
        "print(f\"Tamanho do vocabulário do Word2Vec (com min_count={MIN_COUNT}): {vocab_size_w2v} palavras\")\n",
        "\n",
        "# Testar o modelo Word2Vec\n",
        "try:\n",
        "    print(\"\\nPalavras mais similares a 'computer':\")\n",
        "    print(w2v_model.wv.most_similar('computer'))\n",
        "except KeyError:\n",
        "    print(\"'computer' não está no vocabulário (provavelmente filtrado pelo min_count)\")\n",
        "\n",
        "try:\n",
        "    print(\"\\nPalavras mais similares a 'crypto':\")\n",
        "    print(w2v_model.wv.most_similar('crypto'))\n",
        "except KeyError:\n",
        "    print(\"'crypto' não está no vocabulário\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXVoefDDxAFW"
      },
      "source": [
        "## Passo 3: Preparar Dados para o LSTM (Keras)\n",
        "\n",
        "Agora, fazemos o processo padrão do Keras: tokenizar e padronizar (padding) as sequências. É **crucial** que o `Tokenizer` do Keras seja ajustado *apenas* nos dados de treino para evitar vazamento de dados (data leakage)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E_ujkxkxAFZ",
        "outputId": "47523553-cc8f-4959-98b4-723b21771287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do vocabulário do Keras: 10000\n",
            "Formato dos dados de treino padronizados: (1571, 250)\n"
          ]
        }
      ],
      "source": [
        "# Célula 5: Tokenização e Padding do Keras\n",
        "\n",
        "# Parâmetros do Keras\n",
        "MAX_PALAVRAS_VOCAB = 10000 # Tamanho máximo do vocabulário para o Keras\n",
        "MAX_COMPRIMENTO_SEQ = 250  # Comprimento máximo de cada documento (o mesmo de antes)\n",
        "\n",
        "# 1. Tokenizar (usando Keras)\n",
        "tokenizer = Tokenizer(num_words=MAX_PALAVRAS_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_text) # Ajustar SOMENTE no treino\n",
        "\n",
        "# Converter textos em sequências de inteiros\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
        "\n",
        "# 2. Padronizar (Padding)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_COMPRIMENTO_SEQ, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_COMPRIMENTO_SEQ, padding='post', truncating='post')\n",
        "\n",
        "# Guardar o índice de palavras do Keras\n",
        "word_index = tokenizer.word_index\n",
        "# O vocabulário real do Keras será o min(MAX_PALAVRAS_VOCAB, len(word_index)) + 1 (para o padding)\n",
        "vocab_size_keras = min(MAX_PALAVRAS_VOCAB, len(word_index) + 1)\n",
        "\n",
        "print(f\"Tamanho do vocabulário do Keras: {vocab_size_keras}\")\n",
        "print(f\"Formato dos dados de treino padronizados: {X_train_pad.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7t5gZOxxAFg"
      },
      "source": [
        "## Passo 4: Criar a Matriz de Embedding (A \"Ponte\")\n",
        "\n",
        "Este é o passo crucial.\n",
        "\n",
        "Vamos criar uma matriz onde `matriz[i]` conterá o vetor Word2Vec para a palavra de índice `i` no `Tokenizer` do Keras. Se uma palavra do Keras não existir no nosso modelo Word2Vec (talvez por ter sido filtrada pelo `min_count`), seu vetor permanecerá como zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEMK72VBxAFh",
        "outputId": "0f3eaa3a-bf26-4c56-c2b8-2c2ce638ba25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Embedding criada com formato: (10000, 100)\n",
            "9071 palavras do Keras foram encontradas no Word2Vec.\n",
            "928 palavras não foram encontradas (ficarão como vetores de zero).\n"
          ]
        }
      ],
      "source": [
        "# Célula 6: Construção da Matriz de Embedding\n",
        "\n",
        "# Inicializar uma matriz de zeros\n",
        "# Usamos 'vocab_size_keras' que já considera o limite MAX_PALAVRAS_VOCAB\n",
        "embedding_matrix = np.zeros((vocab_size_keras, DIM_EMBEDDING))\n",
        "\n",
        "palavras_encontradas = 0\n",
        "palavras_nao_encontradas = 0\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_PALAVRAS_VOCAB: # Não ultrapassar o limite de vocabulário\n",
        "        continue\n",
        "\n",
        "    if word in w2v_model.wv: # Se a palavra existe no modelo Word2Vec\n",
        "        embedding_matrix[i] = w2v_model.wv[word] # Copia o vetor\n",
        "        palavras_encontradas += 1\n",
        "    else:\n",
        "        palavras_nao_encontradas += 1 # A palavra fica com vetor de zeros\n",
        "\n",
        "print(f\"Matriz de Embedding criada com formato: {embedding_matrix.shape}\")\n",
        "print(f\"{palavras_encontradas} palavras do Keras foram encontradas no Word2Vec.\")\n",
        "print(f\"{palavras_nao_encontradas} palavras não foram encontradas (ficarão como vetores de zero).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MmVVM2ixAFk"
      },
      "source": [
        "## Passo 5: Construir o Modelo LSTM\n",
        "\n",
        "Agora, construímos o modelo LSTM. A diferença está na camada `Embedding`:\n",
        "1.  Passamos `weights=[embedding_matrix]` para carregar nossos pesos pré-treinados.\n",
        "2.  Definimos `trainable=False` para \"congelar\" esses pesos. O modelo só treinará as camadas LSTM e Densa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "wF7Wf9BtxAFl",
        "outputId": "2028d10e-cf0d-4587-8fd0-2f4607ea0fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura do Modelo:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Modelo_Word2Vec_LSTM\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Modelo_Word2Vec_LSTM\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_2             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_2             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Célula 7: Definindo o modelo LSTM com embeddings pré-treinados\n",
        "\n",
        "modelo_w2v_lstm = Sequential(name=\"Modelo_Word2Vec_LSTM\")\n",
        "\n",
        "# Camada de Embedding - A GRANDE MUDANÇA ESTÁ AQUI\n",
        "modelo_w2v_lstm.add(Embedding(\n",
        "    input_dim=vocab_size_keras,     # Tamanho do vocabulário do Keras\n",
        "    output_dim=DIM_EMBEDDING,       # Dimensão dos vetores (do Word2Vec)\n",
        "    input_length=MAX_COMPRIMENTO_SEQ,\n",
        "    weights=[embedding_matrix],     # Carrega a matriz pré-treinada\n",
        "    trainable=False                 # CONGELA a camada de embedding\n",
        "))\n",
        "\n",
        "modelo_w2v_lstm.add(SpatialDropout1D(0.2))\n",
        "modelo_w2v_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "modelo_w2v_lstm.add(Dense(16, activation='relu'))\n",
        "modelo_w2v_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "modelo_w2v_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(\"Estrutura do Modelo:\")\n",
        "modelo_w2v_lstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN4Et_pcxAFn"
      },
      "source": [
        "## Passo 6: Treinar e Avaliar\n",
        "\n",
        "Finalmente, treinamos e avaliamos o modelo. O processo de treino deve ser mais rápido, pois a camada de Embedding (que geralmente tem muitos parâmetros) não está sendo treinada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm9734J-xAFp",
        "outputId": "7819facb-cdb8-4c84-95ae-fd422c9b8d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Treinando o modelo W2V+LSTM...\n",
            "Epoch 1/100\n",
            "50/50 - 16s - 310ms/step - accuracy: 0.8377 - loss: 0.3669 - val_accuracy: 0.8321 - val_loss: 0.4052\n",
            "Epoch 2/100\n",
            "50/50 - 15s - 298ms/step - accuracy: 0.8370 - loss: 0.3805 - val_accuracy: 0.8244 - val_loss: 0.3748\n",
            "Epoch 3/100\n",
            "50/50 - 15s - 301ms/step - accuracy: 0.8491 - loss: 0.3547 - val_accuracy: 0.8372 - val_loss: 0.3680\n",
            "Epoch 4/100\n",
            "50/50 - 20s - 405ms/step - accuracy: 0.8523 - loss: 0.3490 - val_accuracy: 0.8295 - val_loss: 0.3819\n",
            "Epoch 5/100\n",
            "50/50 - 20s - 399ms/step - accuracy: 0.8555 - loss: 0.3383 - val_accuracy: 0.8346 - val_loss: 0.3642\n",
            "Epoch 6/100\n",
            "50/50 - 14s - 285ms/step - accuracy: 0.8536 - loss: 0.3347 - val_accuracy: 0.8244 - val_loss: 0.3631\n",
            "Epoch 7/100\n",
            "50/50 - 21s - 414ms/step - accuracy: 0.8644 - loss: 0.3155 - val_accuracy: 0.8321 - val_loss: 0.3630\n",
            "Epoch 8/100\n",
            "50/50 - 21s - 416ms/step - accuracy: 0.8593 - loss: 0.3155 - val_accuracy: 0.8270 - val_loss: 0.3559\n",
            "Epoch 9/100\n",
            "50/50 - 14s - 285ms/step - accuracy: 0.8612 - loss: 0.3237 - val_accuracy: 0.8295 - val_loss: 0.3431\n",
            "Epoch 10/100\n",
            "50/50 - 16s - 326ms/step - accuracy: 0.8721 - loss: 0.3018 - val_accuracy: 0.8346 - val_loss: 0.3380\n",
            "Epoch 11/100\n",
            "50/50 - 19s - 379ms/step - accuracy: 0.8651 - loss: 0.3123 - val_accuracy: 0.8372 - val_loss: 0.3467\n",
            "Epoch 12/100\n",
            "50/50 - 14s - 285ms/step - accuracy: 0.8651 - loss: 0.3044 - val_accuracy: 0.8346 - val_loss: 0.3421\n",
            "Epoch 13/100\n",
            "50/50 - 21s - 415ms/step - accuracy: 0.8746 - loss: 0.2919 - val_accuracy: 0.8473 - val_loss: 0.3339\n",
            "Epoch 14/100\n",
            "50/50 - 14s - 286ms/step - accuracy: 0.8619 - loss: 0.3056 - val_accuracy: 0.8422 - val_loss: 0.3332\n",
            "Epoch 15/100\n",
            "50/50 - 21s - 412ms/step - accuracy: 0.8727 - loss: 0.2922 - val_accuracy: 0.8575 - val_loss: 0.3328\n",
            "Epoch 16/100\n",
            "50/50 - 15s - 306ms/step - accuracy: 0.8625 - loss: 0.2859 - val_accuracy: 0.8295 - val_loss: 0.3515\n",
            "Epoch 17/100\n",
            "50/50 - 20s - 405ms/step - accuracy: 0.8746 - loss: 0.2835 - val_accuracy: 0.8422 - val_loss: 0.3378\n",
            "Epoch 18/100\n",
            "50/50 - 14s - 286ms/step - accuracy: 0.8721 - loss: 0.2750 - val_accuracy: 0.8499 - val_loss: 0.3125\n",
            "Epoch 19/100\n",
            "50/50 - 14s - 286ms/step - accuracy: 0.8746 - loss: 0.2764 - val_accuracy: 0.8422 - val_loss: 0.3205\n",
            "Epoch 20/100\n",
            "50/50 - 15s - 302ms/step - accuracy: 0.8771 - loss: 0.2790 - val_accuracy: 0.8448 - val_loss: 0.3091\n",
            "Epoch 21/100\n",
            "50/50 - 15s - 297ms/step - accuracy: 0.8842 - loss: 0.2653 - val_accuracy: 0.8473 - val_loss: 0.3027\n",
            "Epoch 22/100\n",
            "50/50 - 15s - 295ms/step - accuracy: 0.8810 - loss: 0.2670 - val_accuracy: 0.8473 - val_loss: 0.3059\n",
            "Epoch 23/100\n",
            "50/50 - 16s - 316ms/step - accuracy: 0.8912 - loss: 0.2580 - val_accuracy: 0.8499 - val_loss: 0.3079\n",
            "Epoch 24/100\n",
            "50/50 - 20s - 408ms/step - accuracy: 0.8892 - loss: 0.2579 - val_accuracy: 0.8473 - val_loss: 0.3060\n",
            "Epoch 25/100\n",
            "50/50 - 15s - 303ms/step - accuracy: 0.8937 - loss: 0.2440 - val_accuracy: 0.8473 - val_loss: 0.3025\n",
            "Epoch 26/100\n",
            "50/50 - 14s - 287ms/step - accuracy: 0.8778 - loss: 0.2797 - val_accuracy: 0.8321 - val_loss: 0.3194\n",
            "Epoch 27/100\n",
            "50/50 - 22s - 433ms/step - accuracy: 0.8829 - loss: 0.2569 - val_accuracy: 0.8524 - val_loss: 0.2968\n",
            "Epoch 28/100\n",
            "50/50 - 19s - 385ms/step - accuracy: 0.8822 - loss: 0.2598 - val_accuracy: 0.8499 - val_loss: 0.2983\n",
            "Epoch 29/100\n",
            "50/50 - 14s - 289ms/step - accuracy: 0.8784 - loss: 0.2572 - val_accuracy: 0.8448 - val_loss: 0.3048\n",
            "Epoch 30/100\n",
            "50/50 - 21s - 412ms/step - accuracy: 0.8912 - loss: 0.2479 - val_accuracy: 0.8651 - val_loss: 0.2837\n",
            "Epoch 31/100\n",
            "50/50 - 15s - 295ms/step - accuracy: 0.8791 - loss: 0.2496 - val_accuracy: 0.8524 - val_loss: 0.3087\n",
            "Epoch 32/100\n",
            "50/50 - 22s - 430ms/step - accuracy: 0.8822 - loss: 0.2484 - val_accuracy: 0.8626 - val_loss: 0.2859\n",
            "Epoch 33/100\n",
            "50/50 - 16s - 321ms/step - accuracy: 0.8867 - loss: 0.2546 - val_accuracy: 0.8473 - val_loss: 0.2992\n",
            "Epoch 34/100\n",
            "50/50 - 16s - 316ms/step - accuracy: 0.8873 - loss: 0.2434 - val_accuracy: 0.8601 - val_loss: 0.2788\n",
            "Epoch 35/100\n",
            "50/50 - 16s - 327ms/step - accuracy: 0.8880 - loss: 0.2436 - val_accuracy: 0.8550 - val_loss: 0.2895\n",
            "Epoch 36/100\n",
            "50/50 - 19s - 382ms/step - accuracy: 0.8912 - loss: 0.2413 - val_accuracy: 0.8626 - val_loss: 0.2835\n",
            "Epoch 37/100\n",
            "50/50 - 21s - 429ms/step - accuracy: 0.8912 - loss: 0.2310 - val_accuracy: 0.8601 - val_loss: 0.2860\n",
            "Epoch 38/100\n",
            "50/50 - 15s - 306ms/step - accuracy: 0.8943 - loss: 0.2371 - val_accuracy: 0.8499 - val_loss: 0.2954\n",
            "Epoch 39/100\n",
            "50/50 - 15s - 291ms/step - accuracy: 0.8899 - loss: 0.2465 - val_accuracy: 0.8601 - val_loss: 0.2910\n",
            "Epoch 40/100\n",
            "50/50 - 22s - 432ms/step - accuracy: 0.8918 - loss: 0.2340 - val_accuracy: 0.8728 - val_loss: 0.2761\n",
            "Epoch 41/100\n",
            "50/50 - 20s - 406ms/step - accuracy: 0.8892 - loss: 0.2304 - val_accuracy: 0.8702 - val_loss: 0.2763\n",
            "Epoch 42/100\n",
            "50/50 - 15s - 301ms/step - accuracy: 0.8956 - loss: 0.2312 - val_accuracy: 0.8651 - val_loss: 0.2788\n",
            "Epoch 43/100\n",
            "50/50 - 16s - 314ms/step - accuracy: 0.9032 - loss: 0.2131 - val_accuracy: 0.8601 - val_loss: 0.2859\n",
            "Epoch 44/100\n",
            "50/50 - 16s - 315ms/step - accuracy: 0.8975 - loss: 0.2266 - val_accuracy: 0.8626 - val_loss: 0.2755\n",
            "Epoch 45/100\n",
            "50/50 - 15s - 290ms/step - accuracy: 0.8962 - loss: 0.2311 - val_accuracy: 0.8779 - val_loss: 0.2727\n",
            "Epoch 46/100\n",
            "50/50 - 21s - 424ms/step - accuracy: 0.8975 - loss: 0.2271 - val_accuracy: 0.8677 - val_loss: 0.2706\n",
            "Epoch 47/100\n",
            "50/50 - 16s - 312ms/step - accuracy: 0.8982 - loss: 0.2131 - val_accuracy: 0.8499 - val_loss: 0.2969\n",
            "Epoch 48/100\n",
            "50/50 - 16s - 320ms/step - accuracy: 0.8937 - loss: 0.2277 - val_accuracy: 0.8753 - val_loss: 0.2732\n",
            "Epoch 49/100\n",
            "50/50 - 14s - 289ms/step - accuracy: 0.9001 - loss: 0.2125 - val_accuracy: 0.8804 - val_loss: 0.2620\n",
            "Epoch 50/100\n",
            "50/50 - 21s - 421ms/step - accuracy: 0.8988 - loss: 0.2199 - val_accuracy: 0.8906 - val_loss: 0.2768\n",
            "Epoch 51/100\n",
            "50/50 - 21s - 412ms/step - accuracy: 0.8931 - loss: 0.2283 - val_accuracy: 0.8651 - val_loss: 0.2739\n",
            "Epoch 52/100\n",
            "50/50 - 16s - 310ms/step - accuracy: 0.8975 - loss: 0.2102 - val_accuracy: 0.8626 - val_loss: 0.2759\n",
            "Epoch 53/100\n",
            "50/50 - 19s - 388ms/step - accuracy: 0.9007 - loss: 0.2197 - val_accuracy: 0.8753 - val_loss: 0.2744\n",
            "Epoch 54/100\n",
            "50/50 - 21s - 420ms/step - accuracy: 0.8988 - loss: 0.2138 - val_accuracy: 0.8651 - val_loss: 0.2834\n",
            "Epoch 55/100\n",
            "50/50 - 20s - 402ms/step - accuracy: 0.9064 - loss: 0.2082 - val_accuracy: 0.8779 - val_loss: 0.2712\n",
            "Epoch 56/100\n",
            "50/50 - 21s - 415ms/step - accuracy: 0.9026 - loss: 0.2084 - val_accuracy: 0.8855 - val_loss: 0.2601\n",
            "Epoch 57/100\n",
            "50/50 - 15s - 303ms/step - accuracy: 0.8982 - loss: 0.2235 - val_accuracy: 0.8779 - val_loss: 0.2638\n",
            "Epoch 58/100\n",
            "50/50 - 15s - 299ms/step - accuracy: 0.8931 - loss: 0.2092 - val_accuracy: 0.8753 - val_loss: 0.2652\n",
            "Epoch 59/100\n",
            "50/50 - 15s - 309ms/step - accuracy: 0.9077 - loss: 0.2025 - val_accuracy: 0.8855 - val_loss: 0.2575\n",
            "Epoch 60/100\n",
            "50/50 - 21s - 416ms/step - accuracy: 0.9090 - loss: 0.2011 - val_accuracy: 0.8880 - val_loss: 0.2390\n",
            "Epoch 61/100\n",
            "50/50 - 15s - 298ms/step - accuracy: 0.9109 - loss: 0.1938 - val_accuracy: 0.8906 - val_loss: 0.2531\n",
            "Epoch 62/100\n",
            "50/50 - 15s - 305ms/step - accuracy: 0.9045 - loss: 0.2052 - val_accuracy: 0.8804 - val_loss: 0.2530\n",
            "Epoch 63/100\n",
            "50/50 - 20s - 391ms/step - accuracy: 0.9064 - loss: 0.1950 - val_accuracy: 0.8982 - val_loss: 0.2422\n",
            "Epoch 64/100\n",
            "50/50 - 15s - 296ms/step - accuracy: 0.9122 - loss: 0.1888 - val_accuracy: 0.8804 - val_loss: 0.2663\n",
            "Epoch 65/100\n",
            "50/50 - 15s - 302ms/step - accuracy: 0.9122 - loss: 0.1974 - val_accuracy: 0.8702 - val_loss: 0.2642\n",
            "Epoch 66/100\n",
            "50/50 - 16s - 318ms/step - accuracy: 0.9198 - loss: 0.1895 - val_accuracy: 0.8880 - val_loss: 0.2483\n",
            "Epoch 67/100\n",
            "50/50 - 15s - 305ms/step - accuracy: 0.9236 - loss: 0.1773 - val_accuracy: 0.8855 - val_loss: 0.2432\n",
            "Epoch 68/100\n",
            "50/50 - 14s - 288ms/step - accuracy: 0.9198 - loss: 0.1847 - val_accuracy: 0.8982 - val_loss: 0.2359\n",
            "Epoch 69/100\n",
            "50/50 - 15s - 296ms/step - accuracy: 0.9153 - loss: 0.1935 - val_accuracy: 0.8779 - val_loss: 0.2436\n",
            "Epoch 70/100\n",
            "50/50 - 21s - 411ms/step - accuracy: 0.9090 - loss: 0.1977 - val_accuracy: 0.8753 - val_loss: 0.2826\n",
            "Epoch 71/100\n",
            "50/50 - 15s - 300ms/step - accuracy: 0.9090 - loss: 0.2016 - val_accuracy: 0.8804 - val_loss: 0.2481\n",
            "Epoch 72/100\n",
            "50/50 - 20s - 405ms/step - accuracy: 0.9179 - loss: 0.1842 - val_accuracy: 0.9033 - val_loss: 0.2427\n",
            "Epoch 73/100\n",
            "50/50 - 22s - 441ms/step - accuracy: 0.9147 - loss: 0.1773 - val_accuracy: 0.8753 - val_loss: 0.2501\n",
            "Epoch 74/100\n",
            "50/50 - 15s - 296ms/step - accuracy: 0.9173 - loss: 0.1822 - val_accuracy: 0.8779 - val_loss: 0.2502\n",
            "Epoch 75/100\n",
            "50/50 - 15s - 296ms/step - accuracy: 0.9230 - loss: 0.1719 - val_accuracy: 0.9033 - val_loss: 0.2556\n",
            "Epoch 76/100\n",
            "50/50 - 16s - 310ms/step - accuracy: 0.9230 - loss: 0.1708 - val_accuracy: 0.8804 - val_loss: 0.2627\n",
            "Epoch 77/100\n",
            "50/50 - 19s - 389ms/step - accuracy: 0.9262 - loss: 0.1727 - val_accuracy: 0.9033 - val_loss: 0.2467\n",
            "Epoch 78/100\n",
            "50/50 - 15s - 302ms/step - accuracy: 0.9153 - loss: 0.1907 - val_accuracy: 0.8855 - val_loss: 0.2690\n",
            "Epoch 79/100\n",
            "50/50 - 20s - 400ms/step - accuracy: 0.9185 - loss: 0.1763 - val_accuracy: 0.8880 - val_loss: 0.2469\n",
            "Epoch 80/100\n",
            "50/50 - 15s - 291ms/step - accuracy: 0.9236 - loss: 0.1718 - val_accuracy: 0.8906 - val_loss: 0.2407\n",
            "Epoch 81/100\n",
            "50/50 - 15s - 302ms/step - accuracy: 0.9147 - loss: 0.1841 - val_accuracy: 0.8779 - val_loss: 0.2676\n",
            "Epoch 82/100\n",
            "50/50 - 20s - 397ms/step - accuracy: 0.9262 - loss: 0.1717 - val_accuracy: 0.8804 - val_loss: 0.2504\n",
            "Epoch 83/100\n",
            "50/50 - 15s - 293ms/step - accuracy: 0.9211 - loss: 0.1766 - val_accuracy: 0.8982 - val_loss: 0.2463\n",
            "Epoch 84/100\n",
            "50/50 - 15s - 308ms/step - accuracy: 0.9274 - loss: 0.1699 - val_accuracy: 0.8855 - val_loss: 0.2517\n",
            "Epoch 85/100\n",
            "50/50 - 15s - 307ms/step - accuracy: 0.9300 - loss: 0.1582 - val_accuracy: 0.8931 - val_loss: 0.2406\n",
            "Epoch 86/100\n",
            "50/50 - 21s - 420ms/step - accuracy: 0.9281 - loss: 0.1510 - val_accuracy: 0.9033 - val_loss: 0.2275\n",
            "Epoch 87/100\n",
            "50/50 - 15s - 301ms/step - accuracy: 0.9274 - loss: 0.1652 - val_accuracy: 0.9008 - val_loss: 0.2325\n",
            "Epoch 88/100\n",
            "50/50 - 21s - 418ms/step - accuracy: 0.9313 - loss: 0.1550 - val_accuracy: 0.8931 - val_loss: 0.2345\n",
            "Epoch 89/100\n",
            "50/50 - 15s - 292ms/step - accuracy: 0.9313 - loss: 0.1570 - val_accuracy: 0.8982 - val_loss: 0.2441\n",
            "Epoch 90/100\n",
            "50/50 - 20s - 407ms/step - accuracy: 0.9338 - loss: 0.1565 - val_accuracy: 0.8957 - val_loss: 0.2357\n",
            "Epoch 91/100\n",
            "50/50 - 14s - 290ms/step - accuracy: 0.9249 - loss: 0.1554 - val_accuracy: 0.9059 - val_loss: 0.2400\n",
            "Epoch 92/100\n",
            "50/50 - 22s - 436ms/step - accuracy: 0.9293 - loss: 0.1540 - val_accuracy: 0.8855 - val_loss: 0.2444\n",
            "Epoch 93/100\n",
            "50/50 - 19s - 386ms/step - accuracy: 0.9293 - loss: 0.1575 - val_accuracy: 0.8906 - val_loss: 0.2489\n",
            "Epoch 94/100\n",
            "50/50 - 15s - 292ms/step - accuracy: 0.9281 - loss: 0.1517 - val_accuracy: 0.8880 - val_loss: 0.2571\n",
            "Epoch 95/100\n",
            "50/50 - 14s - 288ms/step - accuracy: 0.9255 - loss: 0.1546 - val_accuracy: 0.8804 - val_loss: 0.2543\n",
            "Epoch 96/100\n",
            "50/50 - 15s - 299ms/step - accuracy: 0.9306 - loss: 0.1579 - val_accuracy: 0.9109 - val_loss: 0.2369\n",
            "Epoch 97/100\n",
            "50/50 - 20s - 400ms/step - accuracy: 0.9325 - loss: 0.1560 - val_accuracy: 0.9008 - val_loss: 0.2389\n",
            "Epoch 98/100\n",
            "50/50 - 21s - 413ms/step - accuracy: 0.9287 - loss: 0.1602 - val_accuracy: 0.8931 - val_loss: 0.2497\n",
            "Epoch 99/100\n",
            "50/50 - 17s - 331ms/step - accuracy: 0.9287 - loss: 0.1495 - val_accuracy: 0.8880 - val_loss: 0.2562\n",
            "Epoch 100/100\n",
            "50/50 - 15s - 300ms/step - accuracy: 0.9287 - loss: 0.1540 - val_accuracy: 0.9033 - val_loss: 0.2317\n",
            "\n",
            "Acurácia (Word2Vec + LSTM): 0.9033\n"
          ]
        }
      ],
      "source": [
        "# Célula 8: Treinamento e Avaliação\n",
        "\n",
        "# Converter rótulos para numpy array\n",
        "y_train_np = np.array(y_train)\n",
        "y_test_np = np.array(y_test)\n",
        "\n",
        "print(\"\\nTreinando o modelo W2V+LSTM...\")\n",
        "\n",
        "historico = modelo_w2v_lstm.fit(\n",
        "    X_train_pad,\n",
        "    y_train_np,\n",
        "    epochs=100, # Treinar por mais épocas, já que o embedding está congelado\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_pad, y_test_np),\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Avaliação final\n",
        "loss, acuracia_w2v_lstm = modelo_w2v_lstm.evaluate(X_test_pad, y_test_np, verbose=0)\n",
        "\n",
        "print(f\"\\nAcurácia (Word2Vec + LSTM): {acuracia_w2v_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjObKoDWxAFu"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "Esta abordagem nos permite usar o \"conhecimento\" semântico capturado pelo Word2Vec (treinado de forma não supervisionada) como ponto de partida para um classificador supervisionado (LSTM).\n",
        "\n",
        "**Vantagens:**\n",
        "* **Eficiência de Treino:** Congelar a camada de Embedding reduz drasticamente o número de parâmetros treináveis, tornando o treino do LSTM mais rápido.\n",
        "* **Melhor Desempenho em Dados Pequenos:** Se tivéssemos poucos dados de treino *rotulados*, usar embeddings treinados em um corpus muito maior (não supervisionado) traria uma grande vantagem de generalização."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}